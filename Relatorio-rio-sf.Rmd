---
title: "Trabalho de Aplicação - Rio São Franscisco"
author: 'Yugo Oyama NUSP: 9297784'
date: "14/11/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Introdução

Este trabalho consiste na aplicação de técnicas estatísticas abordadas no curso de Estatística em Altas Dimensões - 2021 em dois bancos de dados que serão explicados detalhadamente mais a frente.

## Chuva e vazão no Rio São Francisco

### Dados

Os dados armazenados no arquivo dados_rio_sf.rdata são referentes a medições de vazão e chuva em estações localizadas na região do rio São Francisco.

```{r}
load("dados_rio_sf.rdata")
```

Dentro deste arquivo, há três variáveis:

treino_sf: conjunto de treino com as medições de vazão e precipitação nas estações consideradas;
estacoes: com informações sobre as estações que coletam os dados;
teste_sf: conjundo com dados que serão usados para avaliar a performance dos modelos preditivos;


### Dados de treinamento

O dataframe dados_treino contem 1717 linhas e 83 colunas. Cada linha contêm medições semanais de vazão em diferentes estações fluviométricas sobre o rio São Francisco e de chuva em estações pluviométricas em regiões próximas do rio. Se a estação é fluviométrica, o dado armazenado é a vazão média registrada na semana correspondente. Caso a estação seja pluviométrica, o dado registrado é a chuva acumulada naquela semana. A primeira coluna, chamada Y, contém a medida de vazão na estação fluviométrica de código 46998000, que corresponde à estação em que se tem interesse em fazer previsão. A vazão na coluna Y corresponde à medição na semana seguinte às demais medições da mesma linha. 

### Estações

O dataframe estações contém informações sobre cada uma das estações que aparecem no dataframe treino_sf. Essas informações estão disponibilizadas apenas a título de curiosidade e não devem ser utilizadas para construir os modelos preditivos. Por exemplo, latitude e longitude, além do tipo da estação (fluviométrica ou pluviométrica) e outros detalhes técnicos de cada uma delas.

### Objetivo

O objetivo desta análise é propor um modelo que consiga realizar boas predições para as medições de vazão na estação 46998000 (coluna Y), dadas as medições tomadas nas estações do sistema na semana anterior (demais colunas). 

### Técnicas

Para esse projeto serão usados modelos lineares com regularização, modelos baseados em árvores, e redes neurais.  

Para comparar os modelos entre si,será utilizado o erro absoluto médio (MAE) e ao final de cada método testado, será adicionado o resultado a uma tabela comparativa.


### Bibliotecas 
```{r}
library(glmnet) # tem as funcoes para lasso, ridge e elasticnet
library(dplyr) # manipular tabelas e banco de dados
library(keras) # redes neurais
library(randomForest) # funcoes para estimar floresta aleatoria

```

### Parâmetros

Para o ajuste do modelo, foi definido que o conjunto de treino seria dividido em conjunto de treino e validação na proporção 8:2, ou seja, 20% do conjunto originalmente de treino foi usado para validação.

```{r}
# Definindo semente e porcentagem da amostra de treino e de validação.
set.seed(1234)

# separando 75% dos dados para treino
ids <- sample(nrow(treino_sf), size = .80*nrow(treino_sf), replace = FALSE) 

```


```{r}
# X matriz com variaveis preditoras (-1 para retirar o intercepto)
X <- model.matrix(Y ~ .,
                  data = treino_sf)[,-1]
  

```

### Modelo Média

De forma a ter uma base para comparar, foi construído um modelo simples que considera todos os valores da estação 46998000, calcula a média e sempre preve que a próxima medição será a média.

```{r}
media <- mean(X[,"`46998000`"])
y_media_dentro <- rep(media,nrow(X[ids,]))

y_media_fora <- rep(media,nrow(X[-ids,]))

(media_erro_dentro <- mean(abs(y_media_dentro - treino_sf$Y[ids])))

(media_erro_fora <- mean(abs((y_media_fora - treino_sf$Y[-ids]))))

```

```{r}
resultados <- data.frame("Media",media_erro_dentro, media_erro_fora)
names(resultados) <- c("modelo", "erro_dentro", "erro_fora")

resultados <- resultados %>% mutate(across(where(is.numeric),round,4))
resultados

```

<!-- ### Modelo Linear -->
<!-- ```{r} -->
<!-- reg_simples<- lm(Y~., data = treino_sf[ids,]) -->

<!-- ``` -->

<!-- ```{r} -->

<!-- y_lm_dentro <- predict(reg_simples, newx = X[ids,]) # valor predito dentro da amostra -->

<!-- y_lm_fora <- predict(reg_simples, newx = X[-ids,]) # valor predito fora da amostra -->
<!-- ``` -->


<!-- ```{r} -->
<!-- (lasso_erro_dentro <- mean(abs(y_lm_dentro - treino_sf$Y[ids]))) -->

<!-- (lasso_erro_fora <- mean(abs(y_lm_fora - treino_sf$Y[-ids]))) -->
<!-- ``` -->

### Lasso

Para criar um modelo de regressão com a penalização lasso, foi utilizada a biblioteca glmnet. Com ela, dentro da amostra de treino, foi ajustado o modelo de regressão com penalização lasso utizando validação cruzada. Em seguida, foi testado o modelo obtido no conjunto de validação e calculado o respectivo erro dentro e fora.

Para a escolha do lambda, existem dois lambdas que são popularmentes usados: o que minimiza o erro gerado pela validação cruzada e o no qual o erro não ultrapassa um desvio padrão do melhor modelo. Com isso, foram testados modelos com cada um dos lambdas e calculados os erros dentro e fora respectivos de cada um.

```{r, eval=FALSE}
cv_lasso <- cv.glmnet(X[ids,], treino_sf$Y[ids], alpha = 1,
                      lambda = c(0.01, 0.1, 1, 2, 10, 25, 50, 75, 100))
# cv_lasso <- cv.glmnet(X[ids,], treino_sf$Y[ids], alpha = 1,
#                       nlambda=500)

# cv_lasso$lambda.min
```

```{r, eval=FALSE}
saveRDS(cv_lasso, "sf_cv_lasso.rds")
```

```{r, eval=TRUE}
cv_lasso <- readRDS("sf_cv_lasso.rds")
```


<!-- ```{r, eval=FALSE} -->
<!-- modelo_lasso <- glmnet(X[ids,], treino_sf$Y[ids], alpha = 1, lambda = cv_lasso$lambda.min) -->
<!-- ``` -->

<!-- ```{r, eval=FALSE} -->
<!-- saveRDS(modelo_lasso, "sf_lasso.rds") -->
<!-- ``` -->

<!-- ```{r, eval=TRUE} -->
<!-- modelo_lasso <- readRDS("sf_lasso.rds") -->
<!-- ``` -->


```{r}
# saida mostra a prob de sair determinado valor

y_lasso_dentro <- predict(cv_lasso, newx = X[ids,],
                          s = cv_lasso$lambda.min) # valor predito dentro da amostra
y_lasso_dentro2 <- predict(cv_lasso, newx = X[ids,],
                          s = cv_lasso$lambda.1se) # valor predito dentro da amostra

y_lasso_fora <- predict(cv_lasso, newx = X[-ids,],
                          s = cv_lasso$lambda.min) # valor predito fora da amostra
y_lasso_fora2 <- predict(cv_lasso, newx = X[-ids,],
                          s = cv_lasso$lambda.1se) # valor predito fora da amostra
```


```{r}
(erro_dentro_lasso <- mean(abs(y_lasso_dentro - treino_sf$Y[ids])))
(erro_dentro_lasso2 <- mean(abs(y_lasso_dentro2 - treino_sf$Y[ids])))

(erro_fora_lasso <- mean(abs((y_lasso_fora - treino_sf$Y[-ids]))))
(erro_fora_lasso2 <- mean(abs((y_lasso_fora2 - treino_sf$Y[-ids]))))
```


```{r}
# resultados <- data.frame("lasso",lasso_erro_dentro, lasso_erro_fora)
# names(resultados) <- c("modelo", "erro_dentro", "erro_fora")
# typeof(resultados[,2])
resultados <- rbind(resultados,data.frame(modelo="Lasso - lambda minimo",erro_dentro=erro_dentro_lasso, erro_fora=erro_fora_lasso))
resultados <- rbind(resultados,data.frame(modelo="Lasso - lambda 1 desvio padrao",erro_dentro=erro_dentro_lasso2, erro_fora=erro_fora_lasso2))
resultados <- resultados %>% mutate(across(where(is.numeric),round,4))
resultados
```



### Modelo de Árvores

Em florestas aleatorias temos interpretabilidade.

```{r}
library(randomForest) # funcoes para estimar floresta aleatoria
```


```{r}
# duplicar o bd e renomear as colunas para rodar as florestas aleatorias
treino_sf2 <- treino_sf
response_col <- which(colnames(treino_sf2) == "Y")
colnames(treino_sf2)[-response_col] <- paste0( "V", colnames(treino_sf2)[-response_col])
```


```{r, eval=FALSE}
modelo_rf <- randomForest(treino_sf2$Y[ids] ~ .,
                    data = treino_sf2[ids, ])
```


```{r, eval=FALSE}
saveRDS(modelo_rf, "sf_rf.rds")
```

```{r}
modelo_rf <- readRDS("sf_rf.rds")
```

A seguir, podemos ver as cinco estações mais importantes e as cinco menos importantes para a predição.

```{r}
# importancia das variaveis
a <- as.data.frame(importance(modelo_rf))
head(a %>% arrange(desc(IncNodePurity)),5)
tail(a %>% arrange(desc(IncNodePurity)),5)
rm(a)
```

Ainda, é possível vizualizar melhor no gráfico a seguir a importância de cada estação.

```{r}
varImpPlot(modelo_rf)
```

```{r}
y_rf_dentro<- predict(modelo_rf, treino_sf2[ids,-1])
y_rf_fora<- predict(modelo_rf, treino_sf2[-ids,-1])
```

```{r}
(erro_dentro_rf <- mean(abs(y_rf_dentro - treino_sf$Y[ids])))

(erro_fora_rf <- mean(abs((y_rf_fora - treino_sf$Y[-ids]))))
```
```{r}
# resultados <- data.frame("lasso",lasso_erro_dentro, lasso_erro_fora)
# names(resultados) <- c("modelo", "erro_dentro", "erro_fora")
# typeof(resultados[,2])
resultados <- rbind(resultados,data.frame(modelo="Floresta Aleatoria",erro_dentro=erro_dentro_rf, erro_fora=erro_fora_rf))
resultados <- resultados %>% mutate(across(where(is.numeric),round,4))
resultados
```


### Redes neurais

Foi utilizada a função de ativação ReLu ao invés da sigmoid por ser computacionalmente mais rápida.
Vamos considerar uma estrutura simples com apenas uma camada oculta.
Vamos considerar 41 unidades na camada oculta, por ser 50% da quantidade de camadas de entrada.

```{r, eval=FALSE}
# Rede Neural -------------------------------------------------------------
library(keras)

# primeiro passo: definir a estrutura que descreve a rede neural
# vamos considerar uma rede com uma unica camada oculta
# contendo 50 unidades e funcao de ativacao ReLU
# dropout layer de 40%
# a ultima camada tem somente uma unidade

modelo_rn <- keras_model_sequential() %>%
  layer_dense(units = 41, # numero de unidades na camada oculta
              activation = "relu", # funcao de ativacao
              input_shape = ncol(X)) %>% # dimensao da entrada
  layer_dropout(rate = 0.4) %>% # taxa de nos nos suprime em cada etapa
  layer_dense(units = 1) # camadas de saida com uma unica unidade pq eh um modelo de regressao

modelo_rn
```


```{r, eval=FALSE}
# segundo passo: especificacoes que controlam o algoritmo de estimacao
modelo_rn %>%
  compile(loss = "mse",   # funcao de custo
          optimizer = optimizer_rmsprop(),  # otimizador
          metrics = list("mean_absolute_error"))   # metrica para avaliar o erro
# a funcao compile() nao muda a variavel R, mas
# comunica as especificacoes para a instancia
# python correspondente que foi criada
```

```{r, eval=FALSE}
# salvar o modelo
save_model_hdf5(modelo_rn, "sf_rn")
```

<!-- ```{r} -->
<!-- callback <- EarlyStopping( -->
<!--     monitor="val_loss", # erro a ser monitorado -->
<!--     min_delta=0, # diminuicao de erro minima -->
<!--     patience=10, # numero de vezes toleradas sem diminuicao do erro -->
<!--     verbose=0, -->
<!--     mode="auto", -->
<!--     baseline=None, -->
<!--     restore_best_weights=False, -->
<!-- ) -->

<!-- ``` -->



```{r, eval=FALSE}
# terceiro passo: ajustar o modelo (estimar os parametros)
history <- modelo_rn %>%
  fit(X[ids,], # preditoras de treino    dados de entrada
      treino_sf$Y[ids],  # resposta de treino
      batch_size = 32, # quantas observacoes escolhidas aleatoriamentes
                       # em cada passo do SGD
      epochs = 150, # uma epoca e' numero de passos do SGD 1500
                     # para processar todos dados de treino
                     # nesse caso, cada epoca tem
                     # length(y[-ids_teste])/32 passos SGD
  #     callback = callback_early_stopping(monitor = "val_loss",
  # min_delta = 0,
  # patience = 20,
  # verbose = 0,
  # mode = c("auto"),
  # baseline = NULL,
  # restore_best_weights = FALSE),
      # dados de validacao para avaliar o progresso do modelo
      validation_data = list(X[-ids,],
                             treino_sf$Y[-ids]))
```


```{r, eval=FALSE}
saveRDS(history, "sf_history.rds")

```



```{r, eval=TRUE}
# carregar o modelo
modelo_rn <- load_model_hdf5("sf_rn")
history <- readRDS("sf_history.rds")
```


```{r, eval=FALSE}
# o grafico abaixo mostra o MAE
# para os dados de treino e teste
plot(history)
```


```{r}
# predicao
y_rn_dentro <- predict(modelo_rn, X[ids, ])
y_rn_fora <- predict(modelo_rn, X[-ids, ])
```


```{r}
# calculo do erro absoluto medio
erro_dentro_rn <- mean(abs (treino_sf$Y[ids] - y_rn_dentro))
erro_fora_rn <- mean(abs (treino_sf$Y[-ids] - y_rn_fora))
# atencao: os resultados variam um pouco pois
# os calculos sao feitos do SGD no python

(resultados <- rbind(resultados,
                     data.frame(modelo = "Rede Neural",
                                erro_dentro = erro_dentro_rn,
                                erro_fora=erro_fora_rn)))
```




### Submissão dos resultados

O dataframe teste_sf está estruturado no mesmo formato que o dataframe treino_sf. A única diferença é que ele não tem a coluna Y, que é aquela que seu modelo deve prever. Uma vez que você fizer a predição para os dados de teste, utilize o código abaixo para criar o arquivo para submissão e avalição. Para que funcione, você deve salvar as predições da vazão em um vetor númerico chamado predicoes, que deve conter 191 elementos. Em seguida, altere o nome do arquivo abaixo, para que tenha seu nome e seu número USP. Atenção: arquivos enviados seguindo uma especificação diferente da apresentada abaixo serão desconsiderados.

```{r}
# duplicar o bd e renomear as colunas para rodar as florestas aleatorias
teste_sf2 <- teste_sf
colnames(teste_sf2) <- paste0( "V", colnames(teste_sf2))

predicoes <- predict(modelo_rf, teste_sf2)
write.csv(data.frame(y_pred = predicoes), file="sf_9297784_yugooyama.csv")

```

A medida utilizada para a avaliação dos resultados será o erro absoluto médio.

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE} 

```

