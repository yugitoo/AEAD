---
title: "Trabalho de Aplicação - Rio São Franscisco"
author: 'Yugo Oyama NUSP: 9297784'
date: "14/11/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Introdução

Este trabalho consiste na aplicação de técnicas estatísticas abordadas no curso de Estatística em Altas Dimensões - 2021 em dois bancos de dados que serão explicados detalhadamente mais a frente.

## Chuva e vazão no Rio São Francisco

### Dados

Os dados armazenados no arquivo dados_rio_sf.rdata são referentes a medições de vazão e chuva em estações localizadas na região do rio São Francisco.

```{r}
load("dados_rio_sf.rdata")
```

Dentro deste arquivo, há três variáveis:

treino_sf: conjunto de treino com as medições de vazão e precipitação nas estações consideradas;
estacoes: com informações sobre as estações que coletam os dados;
teste_sf: conjundo com dados que serão usados para avaliar a performance dos modelos preditivos;


### Dados de treinamento

O dataframe dados_treino contem 1717 linhas e 83 colunas. Cada linha contêm medições semanais de vazão em diferentes estações fluviométricas sobre o rio São Francisco e de chuva em estações pluviométricas em regiões próximas do rio. Se a estação é fluviométrica, o dado armazenado é a vazão média registrada na semana correspondente. Caso a estação seja pluviométrica, o dado registrado é a chuva acumulada naquela semana. A primeira coluna, chamada Y, contém a medida de vazão na estação fluviométrica de código 46998000, que corresponde à estação em que se tem interesse em fazer previsão. A vazão na coluna Y corresponde à medição na semana seguinte às demais medições da mesma linha. 

### Estações

O dataframe estações contém informações sobre cada uma das estações que aparecem no dataframe treino_sf. Essas informações estão disponibilizadas apenas a título de curiosidade e não devem ser utilizadas para construir os modelos preditivos. Por exemplo, latitude e longitude, além do tipo da estação (fluviométrica ou pluviométrica) e outros detalhes técnicos de cada uma delas.

### Objetivo

O objetivo desta análise é propor um modelo que consiga realizar boas predições para as medições de vazão na estação 46998000 (coluna Y), dadas as medições tomadas nas estações do sistema na semana anterior (demais colunas). 

### Técnicas

Para esse projeto serão usados modelos lineares com regularização, modelos baseados em árvores, e redes neurais.  



Para comparar os modelos entre si,será utilizado o erro absoluto médio (MAE) e ao final de cada método testado, será adicionado o resultado a uma tabela comparativa.


### Bibliotecas 
```{r}
library(glmnet) # tem as funcoes para lasso, ridge e elasticnet
library(dplyr) # manipular tabelas e banco de dados
library(keras) # redes neurais

```

```{r}
# Definindo semente e porcentagem da amostra de treino e de validação.
set.seed(1234)

# separando 75% dos dados para treino
ids <- sample(nrow(treino_sf), size = .80*nrow(treino_sf), replace = FALSE) 

```


```{r}
# X matriz com variaveis preditoras (-1 para retirar o intercepto)
X <- model.matrix(Y ~ .,
                  data = treino_sf)[,-1]
  

```

### Modelo Média

De forma a ter uma base para comparar, foi construído um modelo simples que considera todos os valores da estação 46998000, calcula a média e sempre preve que a próxima medição será a média.

```{r}
media <- mean(X[,"`46998000`"])
y_media_dentro <- rep(media,nrow(X[ids,]))

y_media_fora <- rep(media,nrow(X[-ids,]))

(media_erro_dentro <- mean(abs(y_media_dentro - treino_sf$Y[ids])))

(media_erro_fora <- mean(abs((y_media_fora - treino_sf$Y[-ids]))))

```

```{r}
resultados <- data.frame("Media",media_erro_dentro, media_erro_fora)
names(resultados) <- c("modelo", "erro_dentro", "erro_fora")

resultados <- resultados %>% mutate(across(where(is.numeric),round,4))
resultados

```

<!-- ### Modelo Linear -->
<!-- ```{r} -->
<!-- reg_simples<- lm(Y~., data = treino_sf[ids,]) -->

<!-- ``` -->

<!-- ```{r} -->

<!-- y_lm_dentro <- predict(reg_simples, newx = X[ids,]) # valor predito dentro da amostra -->

<!-- y_lm_fora <- predict(reg_simples, newx = X[-ids,]) # valor predito fora da amostra -->
<!-- ``` -->


<!-- ```{r} -->
<!-- (lasso_erro_dentro <- mean(abs(y_lm_dentro - treino_sf$Y[ids]))) -->

<!-- (lasso_erro_fora <- mean(abs(y_lm_fora - treino_sf$Y[-ids]))) -->
<!-- ``` -->

### Lasso
Vamos rodar um LASSO e usar o lambda que minimiza o erro da validacao cruzada.


```{r, eval=FALSE}
cv_lasso <- cv.glmnet(X[ids,], treino_sf$Y[ids], alpha = 1,
                      lambda = c(0.01, 0.1, 1, 2, 10, 25, 50, 75, 100))
# cv_lasso <- cv.glmnet(X[ids,], treino_sf$Y[ids], alpha = 1,
#                       nlambda=500)

cv_lasso$lambda.min
```

```{r, eval=FALSE}
saveRDS(cv_lasso, "sf_cv_lasso.rds")
```

```{r, eval=TRUE}
cv_lasso <- readRDS("sf_cv_lasso.rds")
```


```{r, eval=FALSE}
modelo_lasso <- glmnet(X[ids,], treino_sf$Y[ids], alpha = 1, lambda = cv_lasso$lambda.min)
```

```{r, eval=FALSE}
saveRDS(modelo_lasso, "sf_lasso.rds")
```

```{r, eval=TRUE}
modelo_lasso <- readRDS("sf_lasso.rds")
```

```{r}
# saida mostra a prob de sair determinado valor

y_lasso_dentro <- predict(modelo_lasso, newx = X[ids,],
                          s = cv_lasso$lambda.min) # valor predito dentro da amostra

y_lasso_fora <- predict(modelo_lasso, newx = X[-ids,],
                          s = cv_lasso$lambda.min) # valor predito fora da amostra
```


```{r}
(erro_dentro_lasso <- mean(abs(y_lasso_dentro - treino_sf$Y[ids])))

(erro_fora_lasso <- mean(abs((y_lasso_fora - treino_sf$Y[-ids]))))
```


```{r}
# resultados <- data.frame("lasso",lasso_erro_dentro, lasso_erro_fora)
# names(resultados) <- c("modelo", "erro_dentro", "erro_fora")
# typeof(resultados[,2])
resultados <- rbind(resultados,data.frame(modelo="Lasso",erro_dentro=erro_dentro_lasso, erro_fora=erro_fora_lasso))
resultados <- resultados %>% mutate(across(where(is.numeric),round,4))
resultados
```



### Modelo de Árvores

Em florestas aleatorias temos interpretabilidade.

```{r}
library(randomForest) # funcoes para estimar floresta aleatoria
```


```{r}
# duplicar o bd e renomear as colunas para rodar as florestas aleatorias
treino_sf2 <- treino_sf
response_col <- which(colnames(treino_sf2) == "Y")
colnames(treino_sf2)[-response_col] <- paste0( "V", colnames(treino_sf2)[-response_col])
```


```{r, eval=FALSE}
modelo_rf <- randomForest(treino_sf2$Y[ids] ~ .,
                    data = treino_sf2[ids, ])
```


```{r, eval=FALSE}
saveRDS(modelo_rf, "sf_rf.rds")
```

```{r}
modelo_rf <- readRDS("sf_rf.rds")
```

```{r}
# importancia das variaveis
importance(modelo_rf)
varImpPlot(modelo_rf)
```

```{r}
y_rf_dentro<- predict(modelo_rf, treino_sf2[ids,-1])
y_rf_fora<- predict(modelo_rf, treino_sf2[-ids,-1])
```

```{r}
(erro_dentro_rf <- mean(abs(y_rf_dentro - treino_sf$Y[ids])))

(erro_fora_rf <- mean(abs((y_rf_fora - treino_sf$Y[-ids]))))
```
```{r}
# resultados <- data.frame("lasso",lasso_erro_dentro, lasso_erro_fora)
# names(resultados) <- c("modelo", "erro_dentro", "erro_fora")
# typeof(resultados[,2])
resultados <- rbind(resultados,data.frame(modelo="Floresta Aleatoria",erro_dentro=erro_dentro_rf, erro_fora=erro_fora_rf))
resultados <- resultados %>% mutate(across(where(is.numeric),round,4))
resultados
```


### Redes neurais

Foi utilizada a função de ativação ReLu ao invés da sigmoid por ser computacionalmente mais rápida.
Vamos considerar uma estrutura simples com apenas uma camada oculta.
Vamos considerar 41 unidades na camada oculta, por ser 50% da quantidade de camadas de entrada.

```{r, eval=FALSE}
# Rede Neural -------------------------------------------------------------
library(keras)

# primeiro passo: definir a estrutura que descreve a rede neural
# vamos considerar uma rede com uma unica camada oculta
# contendo 50 unidades e funcao de ativacao ReLU
# dropout layer de 40%
# a ultima camada tem somente uma unidade

modelo_rn <- keras_model_sequential() %>%
  layer_dense(units = 41, # numero de unidades
              activation = "relu", # funcao de ativacao
              input_shape = ncol(X)) %>% # dimensao da entrada
  layer_dropout(rate = 0.4) %>% # taxa de nos nos suprime em cada etapa
  layer_dense(units = 1) # camadas de saida com uma unica unidade pq eh um modelo de regressao

modelo_rn
```


```{r, eval=FALSE}
# segundo passo: especificacoes que controlam o algoritmo de estimacao
modelo_rn %>%
  compile(loss = "mse",   # funcao de custo
          optimizer = optimizer_rmsprop(),  # otimizador
          metrics = list("mean_absolute_error"))   # metrica para avaliar o erro
# a funcao compile() nao muda a variavel R, mas
# comunica as especificacoes para a instancia
# python correspondente que foi criada
```

<!-- ```{r} -->
<!-- callback <- EarlyStopping( -->
<!--     monitor="val_loss", # erro a ser monitorado -->
<!--     min_delta=0, # diminuicao de erro minima -->
<!--     patience=10, # numero de vezes toleradas sem diminuicao do erro -->
<!--     verbose=0, -->
<!--     mode="auto", -->
<!--     baseline=None, -->
<!--     restore_best_weights=False, -->
<!-- ) -->

<!-- ``` -->



```{r, eval=FALSE}
# terceiro passo: ajustar o modelo (estimar os parametros)
history <- modelo_rn %>%
  fit(X[ids,], # preditoras de treino    dados de entrada
      treino_sf$Y[ids],  # resposta de treino
      batch_size = 32, # quantas observacoes escolhidas aleatoriamentes
                       # em cada passo do SGD
      epochs = 1500, # uma epoca e' numero de passos do SGD 1500
                     # para processar todos dados de treino
                     # nesse caso, cada epoca tem
                     # length(y[-ids_teste])/32 passos SGD
      
      # dados de validacao para avaliar o progresso do modelo
      validation_data = list(X[-ids,],
                             treino_sf$Y[-ids]))
saveRDS(history, "sf_history.rds")

```

```{r, eval=FALSE}
# salvar o modelo
save_model_hdf5(modelo_rn, "sf_rn")
save_model_hdf5(history, "sf_history")
```

```{r, eval=TRUE}
# carregar o modelo
modelo_rn <- load_model_hdf5("sf_rn")
# history <- load_model_hdf5("sf_history.rds")
```


```{r, eval=FALSE}
# o grafico abaixo mostra o MAE
# para os dados de treino e teste
plot(history)
```


```{r}
# predicao
pred_rn_dentro <- predict(modelo_rn, X[ids, ])
pred_rn_fora <- predict(modelo_rn, X[-ids, ])
```


```{r}
# calculo do erro absoluto medio
(erro_dentro_rn <- mean(abs (treino_sf$Y[ids] - pred_rn_dentro)))
(erro_fora_rn <- mean(abs (treino_sf$Y[-ids] - pred_rn_fora)))
# atencao: os resultados variam um pouco pois
# os calculos sao feitos do SGD no python

(resultados <- rbind(resultados,
                     data.frame(modelo = "Rede Neural",
                                erro_dentro = erro_dentro_rn,
                                erro_fora=erro_fora_rn)))

```




### Submissão dos resultados

O dataframe teste_sf está estruturado no mesmo formato que o dataframe treino_sf. A única diferença é que ele não tem a coluna Y, que é aquela que seu modelo deve prever. Uma vez que você fizer a predição para os dados de teste, utilize o código abaixo para criar o arquivo para submissão e avalição. Para que funcione, você deve salvar as predições da vazão em um vetor númerico chamado predicoes, que deve conter 191 elementos. Em seguida, altere o nome do arquivo abaixo, para que tenha seu nome e seu número USP. Atenção: arquivos enviados seguindo uma especificação diferente da apresentada abaixo serão desconsiderados.

```{r}
# write.csv(data.frame(y_pred = predicoes), file="sf_nusp_meunome.csv")

```

A medida utilizada para a avaliação dos resultados será o erro absoluto médio.

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE} 

```

