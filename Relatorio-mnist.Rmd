---
title: "Trabalho de Aplicação"
author: 'Yugo Oyama NUSP: 9297784'
date: "14/11/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introdução

Este trabalho consiste na aplicação de técnicas estatísticas abordadas no curso de Estatística em Altas Dimensões - 2021 em dois bancos de dados que serão explicados detalhadamente mais a frente.

## Dados de digitos manuscritos

### Bibliotecas 
```{r}
library(dplyr)
library(glmnet) # tem as funcoes para lasso, ridge e elasticnet
library(keras)
```


### Carregando os Bancos de dados

```{r}
load("dados_mnist.rdata")
```


x_treino: matriz com as 60000 imagens do conjunto de treino;  
y_treino: vetor com os reais valores dos dígitos escritos nas imagens do conjunto de treino (etiquetas);  

Cada linha da matriz x_treino é uma imagem. Aqui, cada imagem está representada como um vetor de dimensao 1x784. Cada coluna indica o tom de cinza do respectivo pixel da imagem (entre 0 - preto e 255 - branco). Para visualizar estes dados como imagem, primeiro você deve transformar a linha com 784 colunas em uma matriz 28x28 e fazer a seguinte operação para rotacionar a figura:

```{r}
matriz <- matrix(x_treino[1,], ncol = 28, byrow = TRUE)

imagem <- t(apply(matriz, 2, rev))
```

Em seguida, para visualizá-la graficamente, utilize o código abaixo.

```{r}
image(1:28, 1:28, imagem, col = gray((0:255)/255), 
        xaxt = 'n', yaxt = 'n', xlab="", ylab="", 
        main = (y_treino[1]))
```

O código e a figura abaixo mostram 36 figuras selecionadas aleatoriamente e suas etiquetas correspondentes.

```{r}
par(mfcol = c(6,6))
par(mar = c(0, 0, 2, 0), xaxs = 'i', yaxs = 'i') 

set.seed(12)

indices <- sample(nrow(x_treino), 36)
for (idx in indices) {
  im <- matrix(x_treino[idx,], nrow=28, byrow = TRUE)
  im <- t(apply(im, 2, rev))
  image(1:28, 1:28, im, col = gray((0:255)/255), 
        xaxt = 'n', yaxt = 'n', xlab="", ylab="", 
        main = (y_treino[idx]))
}
```
Lasso norma 1 e ridge norma 2
Lasso selecao de var
regularizacao, pq soma lambda*norma ao erro dentro


### Lasso
Vamos tentar rodar um LASSO com validação cruzada no conjunto de treino para definir o parâmetro lambda de penalização.

Foi usado o lambda que minimiza o erro da validacao cruzada.

Alpha =1 simboliza lasso

```{r}
# y_treino <- factor(y_treino)
db_digitos <- data.frame(y_treino=y_treino,x_treino)

set.seed(12345)
X <- model.matrix(db_digitos[,1] ~ .,
                  data = db_digitos[,-1])[,-1] # X deve ser uma matrix sem intercepto
```


```{r}
# separando 75% dos dados para treino
ids <- sample(nrow(db_digitos), size = .75*nrow(db_digitos), replace = FALSE)
# ids <- sample(nrow(db_digitos), size = .03*nrow(db_digitos), replace = FALSE)
```

```{r}
# seq(30)
# lambda = c(0.01, 0.1, 1, 2, 10, 25, 50, 75, 100)
```

Foi testado permitir que a função cv.glmnet que ajusta modelo de regressão com validação cruzada usando o parâmetro alpha=1 correspondente a penalidade Lasso e ajustou-se tanto 30 como 50 lambdas diferentes.

```{r}
cv_lasso <- cv.glmnet(X[ids,], as.factor(db_digitos$y_treino[ids]), family = "multinomial", alpha = 1,
                      type.measure = "class", trace.it = TRUE, nlambda = 50, maxit = 10000)

cv_lasso$lambda.min
cv_lasso$lambda.1se
# plot(cv_lasso, cex.lab = 1.3)

saveRDS(cv_lasso, "mnist_lasso2.rds")
```




```{r}
# lasso <- glmnet(X[ids,], as.factor(db_digitos$y_treino[ids]), alpha = 1, lambda = 0.05, family = "multinomial", intercept = FALSE)
```


```{r,eval=FALSE}
saveRDS(cv_lasso, "mnist_lasso.rds")
```

```{r, eval=FALSE}
cv_lasso <- readRDS("mnist_lasso.rds")
```



```{r}
cv_lasso <-readRDS("mnist_lasso.rds")

cv_lasso2 <-readRDS("mnist_lasso2.rds")

y_lasso_dentro <- predict(cv_lasso, newx = X[ids,], 
                          s = cv_lasso$lambda.min, type = "class") # valor predito dentro da amostra

y_lasso_dentro1.2 <- predict(cv_lasso, newx = X[ids,],
                          s = cv_lasso$lambda.1se, type = "class") # valor predito dentro da amostra

y_lasso_dentro2 <- predict(cv_lasso2, newx = X[ids,],
                          s = cv_lasso2$lambda.min, type = "class") # valor predito dentro da amostra

y_lasso_dentro2.2 <- predict(cv_lasso2, newx = X[ids,],
                          s = cv_lasso2$lambda.1se, type = "class") # valor predito dentro da amostra

```


```{r}
# comparativo: observado vs predito (dentro da amostra)
(tabela_tr <- table(predito = y_lasso_dentro, observado = y_treino[ids]))

```


```{r}
#
y_lasso_fora <- predict(cv_lasso, newx = X[-ids,],
                        s = cv_lasso$lambda.min, type = "class") # valor predito fora da amostra

y_lasso_fora1.2 <- predict(cv_lasso, newx = X[-ids,],
                        s = cv_lasso$lambda.1se, type = "class") # valor 

y_lasso_fora2 <- predict(cv_lasso, newx = X[-ids,],
                        s = cv_lasso2$lambda.min, type = "class") # valor predito fora da amostra

y_lasso_fora2.2 <- predict(cv_lasso, newx = X[-ids,],
                        s = cv_lasso2$lambda.1se, type = "class") # valor 

```


```{r}
lasso_ac_dentro<- mean(y_lasso_dentro==y_treino[ids])
lasso_ac_dentro1.2<- mean(y_lasso_dentro1.2==y_treino[ids])
lasso_ac_fora<- mean(y_lasso_fora==y_treino[-ids])
lasso_ac_fora1.2<- mean(y_lasso_fora1.2==y_treino[-ids])

lasso_ac_dentro2<- mean(y_lasso_dentro2==y_treino[ids])
lasso_ac_dentro2.2<- mean(y_lasso_dentro2.2==y_treino[ids])
lasso_ac_fora2<- mean(y_lasso_fora2==y_treino[-ids])
lasso_ac_fora2.2<- mean(y_lasso_fora2.2==y_treino[-ids])


```

```{r}
resultados <- data.frame("Lasso - Lambda minimo",lasso_ac_dentro, lasso_ac_fora)
names(resultados) <- c("modelo", "acuracia_dentro", "acuracia_fora")

resultados <- rbind(resultados,data.frame(modelo="Lasso - Lambda 1 desvio padrao",acuracia_dentro=lasso_ac_dentro1.2, acuracia_fora=lasso_ac_fora1.2))


resultados <- rbind(resultados,data.frame(modelo="Lasso2 - Lambda minimo padrao",acuracia_dentro=lasso_ac_dentro2, acuracia_fora=lasso_ac_fora2))

resultados <- rbind(resultados,data.frame(modelo="Lasso2 - Lambda 1 desvio padrao",acuracia_dentro=lasso_ac_dentro2.2, acuracia_fora=lasso_ac_fora2.2))


resultados <- resultados %>% mutate(across(where(is.numeric),round,4))
resultados

```



### Modelo de Árvores
```{r}
library(tree) # funcoes para estimar arvore de reg/class
library(randomForest) # funcoes para estimar floresta aleatoria

```


```{r}
modelo_rf <- randomForest(factor(db_digitos$y_treino[ids]) ~ .,
                    data = db_digitos[ids, ], do.trace=TRUE)
```

```{r, eval=FALSE}
saveRDS(modelo_rf, "mnist_rf.rds")
```

```{r}
modelo_rf <- readRDS("mnist_rf.rds")
```


```{r}
# importancia das variaveis
importance(modelo_rf)
varImpPlot(modelo_rf)
```

A seguir, podemos ver as cinco estações mais importantes e as cinco menos importantes para a predição.

```{r}
# importancia das variaveis
a <- as.data.frame(importance(modelo_rf))
head(a %>% arrange(desc(MeanDecreaseGini)),5)
tail(a %>% arrange(desc(MeanDecreaseGini)),5)
rm(a)
```

Ainda, é possível vizualizar melhor no gráfico a seguir a importância de cada estação.

```{r}
varImpPlot(modelo_rf)
```

```{r}
y_rf_dentro<- predict(modelo_rf, db_digitos[ids,-1],type="class")
y_rf_fora<- predict(modelo_rf, db_digitos[-ids,-1],type="class")
```


```{r}
# acuracia
rf_ac_dentro <- mean(y_rf_dentro == db_digitos$y_treino[ids])
rf_ac_fora <- mean(y_rf_fora == db_digitos$y_treino[-ids])
```


```{r}

# resultados <- data.frame("Floresta Aleatoria",rf_ac_dentro, rf_ac_fora)
# names(resultados) <- c("modelo", "acuracia_dentro", "acuracia_fora")

# atualizacao do dataframe de resultados
resultados <- rbind(resultados,data.frame(modelo="Floresta aleatoria",acuracia_dentro=rf_ac_dentro, acuracia_fora=rf_ac_fora))
resultados <- resultados %>% mutate(across(where(is.numeric),round,4))
resultados

```

### Redes neurais
Como temos mais de uma classificação, foi utilizado a função softmax como função de ativação.

```{r}
library(keras)

X <- model.matrix(db_digitos[,1] ~ .,
                  data = db_digitos[,-1]) # X deve ser uma matrix

# reshape
# library(Corbi)
# x_train <- submatrix(x_treino,ids,1:784)
# x_test <- submatrix(x_treino,-ids,1:784)

x_train <- X[ids,]
x_test <- X[-ids,]

# rescale
x_train <- x_train / 255
x_test <- x_test / 255

```

```{r}
y_train <- to_categorical(y_treino[ids], 10)
y_test <- to_categorical(y_treino[-ids], 10)
```



```{r, eval=FALSE}
# Rede Neural -------------------------------------------------------------
# library(keras)

# primeiro passo: definir a estrutura que descreve a rede neural
# vamos considerar uma rede com uma unica camada oculta
# contendo 50 unidades e funcao de ativacao ReLU
# dropout layer de 40%
# a ultima camada tem somente uma unidade

modelo_rn <- keras_model_sequential()
modelo_rn %>%
  layer_dense(units = 256, # numero de unidades
              activation = "relu", # funcao de ativacao
              input_shape = ncol(x_train)) %>% # dimensao da entrada
  layer_dropout(rate = 0.4) %>% # taxa de nos nos suprime em cada etapa
  layer_dense(units = 128, activation = 'relu') %>%
  layer_dropout(rate = 0.3) %>%
  layer_dense(units = 10, # camadas de saida com uma unica unidade pq eh um modelo de classificacao com 10 categorias
              activation = "softmax") 

modelo_rn
```



```{r, eval=FALSE}
# segundo passo: especificacoes que controlam o algoritmo de estimacao
modelo_rn %>%
  compile(loss = "categorical_crossentropy",   # funcao de custo
          optimizer = optimizer_rmsprop(),  # otimizador
          metrics = c('accuracy'))   # metrica para avaliar o erro
# a funcao compile() nao muda a variavel R, mas
# comunica as especificacoes para a instancia
# python correspondente que foi criada
```


```{r, eval=FALSE}
# salvar o modelo
save_model_hdf5(modelo_rn, "mnist_rn")
```

Ajustando o tamanho do batch para que a velocidade de cada um e a do final sejam semelhantes. 32 mostrou-se pequeno, entao aumentou

```{r, eval=FALSE}
# terceiro passo: ajustar o modelo (estimar os parametros)
history <- modelo_rn %>%
  fit(x_train, # preditoras de treino    dados de entrada
      y_train,  # resposta de treino
      batch_size = 128, # quantas observacoes escolhidas aleatoriamentes
                       # em cada passo do SGD
      epochs = 30, # uma epoca e' numero de passos do SGD 30
                     # para processar todos dados de treino
                     # nesse caso, cada epoca tem
                     # num de obs/batch passos pra completar uma epoca 
      verbose=1,
  #     callback = callback_early_stopping(monitor = "val_loss",
  # min_delta = 0,
  # patience = 20,
  # verbose = 0,
  # mode = c("auto"),
  # baseline = NULL,
  # restore_best_weights = FALSE),
      # dados de validacao para avaliar o progresso do modelo
      validation_data = list(x_test,
                             y_test))
```

```{r, eval=FALSE}
saveRDS(history, "mnist_history.rds")

```


```{r, eval=TRUE}
# carregar o modelo
modelo_rn <- load_model_hdf5("mnis_rn")
# history <- readRds("mnist_history.rds")
```


```{r}
rn_ac_dentro <- modelo_rn %>% evaluate(x_train, y_train)
rn_ac_fora <- modelo_rn %>% evaluate(x_test, y_test)
```


```{r}
# predicao

y_rn_dentro <- modelo_rn %>% predict(x_treino) %>% k_argmax()
y_rn_fora <- modelo_rn %>% predict(x_test) %>% k_argmax()
```



```{r}
# atualizacao do dataframe de resultados
resultados <- rbind(resultados,data.frame(modelo="Redes Neurais",acuracia_dentro=rn_ac_dentro[2], acuracia_fora=rn_ac_fora[2]))
resultados <- resultados %>% mutate(across(where(is.numeric),round,4))
resultados

```

### Avaliação dos modelos

Para avaliar os modelos, será utilizada a acurácia (erro total de classificação).



1- Modelos lineares com regularização 

2- Modelos baseados em árvores (bagging, florestas aleatórias ou boosting) 

3- Redes neurais 



### Conjunto de teste

Posteriormente, vamos disponibilizar um conjunto de dados de teste, que estará organizado no mesmo formato que o conjunto x_treino. Entretanto, para este conjunto de dados de teste, você não terá acesso às verdadeiras etiquetas de cada imagem. Sua tarefa é estimar um modelo preditivo, realizar predições para as observações do conjunto de teste e submeter um arquivo .csv com o resultado. A medida utilizada para a avaliação dos resultados será a acurácia, isto é, a proporção de imagens corretamente classificadas.
Submissão dos resultados

Em posse do arquivo de dados de teste, use o código abaixo para criar o arquivo para submissão dos seus resultados. Para que funcione, você deverá salvar a predição das imagens de teste em um vetor chamado predicoes. Em seguida, altere o nome do arquivo abaixo, para que tenha seu nome e seu número USP. Arquivos enviados seguindo uma especificação diferente da apresentada abaixo serão desconsiderados.



Submissão dos resultados

Em posse do arquivo de dados de teste, use o código abaixo para criar o arquivo para submissão dos seus resultados. Para que funcione, você deverá salvar a predição das imagens de teste em um vetor chamado predicoes. Em seguida, altere o nome do arquivo abaixo, para que tenha seu nome e seu número USP. Arquivos enviados seguindo uma especificação diferente da apresentada abaixo serão desconsiderados.

```{r}
# write.csv(data.frame(y_pred = predicoes), file="mnist_9297784_yugooyama.csv")

```
