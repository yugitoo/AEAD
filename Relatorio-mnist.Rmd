---
title: "Trabalho de Aplicação"
author: 'Yugo Oyama NUSP: 9297784'
date: "14/11/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introdução

Este trabalho consiste na aplicação de técnicas estatísticas abordadas no curso de Estatística em Altas Dimensões - 2021 em dois bancos de dados que serão explicados detalhadamente mais a frente.

## Dados de digitos manuscritos

### Bibliotecas 
```{r}
library(glmnet) # tem as funcoes para lasso, ridge e elasticnet
```


### Carregando os Bancos de dados

```{r}
load("dados_mnist.rdata")
```


x_treino: matriz com as 60000 imagens do conjunto de treino;  
y_treino: vetor com os reais valores dos dígitos escritos nas imagens do conjunto de treino (etiquetas);  

Cada linha da matriz x_treino é uma imagem. Aqui, cada imagem está representada como um vetor de dimensao 1x784. Cada coluna indica o tom de cinza do respectivo pixel da imagem (entre 0 - preto e 255 - branco). Para visualizar estes dados como imagem, primeiro você deve transformar a linha com 784 colunas em uma matriz 28x28 e fazer a seguinte operação para rotacionar a figura:

```{r}
matriz <- matrix(x_treino[1,], ncol = 28, byrow = TRUE)

imagem <- t(apply(matriz, 2, rev))
```

Em seguida, para visualizá-la graficamente, utilize o código abaixo.

```{r}
image(1:28, 1:28, imagem, col = gray((0:255)/255), 
        xaxt = 'n', yaxt = 'n', xlab="", ylab="", 
        main = (y_treino[1]))
```

O código e a figura abaixo mostram 36 figuras selecionadas aleatoriamente e suas etiquetas correspondentes.

```{r}
par(mfcol = c(6,6))
par(mar = c(0, 0, 2, 0), xaxs = 'i', yaxs = 'i') 

set.seed(12)

indices <- sample(nrow(x_treino), 36)
for (idx in indices) {
  im <- matrix(x_treino[idx,], nrow=28, byrow = TRUE)
  im <- t(apply(im, 2, rev))
  image(1:28, 1:28, im, col = gray((0:255)/255), 
        xaxt = 'n', yaxt = 'n', xlab="", ylab="", 
        main = (y_treino[idx]))
}
```
Lasso norma 1 e ridge norma 2
Lasso selecao de var
regularizacao, pq soma lambda*norma ao erro dentro


### Lasso
Vamos tentar rodar um LASSO com validação cruzada no conjunto de treino para definir o parâmetro lambda de penalização.

Foi usado o lambda que minimiza o erro da validacao cruzada.

Alpha =1 simboliza lasso

```{r}
# y_treino <- factor(y_treino)
db_digitos <- data.frame(y_treino=y_treino,x_treino)

set.seed(12345)
X <- model.matrix( ~ .-1,
                  data = db_digitos)[,-1] # X deve ser uma matrix
```


```{r}
# separando 75% dos dados para treino
ids <- sample(nrow(db_digitos), size = .007*nrow(db_digitos), replace = FALSE)
```


```{r}
cv_lasso <- cv.glmnet(X[ids,], as.factor(db_digitos$y_treino[ids]), family = "multinomial", alpha = 1,
                      type.measure = "class")

cv_lasso$lambda.min
plot(cv_lasso, cex.lab = 1.3)
```




```{r}
lasso <- glmnet(X[ids,], as.factor(db_digitos$y_treino[ids]), alpha = 1, lambda = cv_lasso$lambda.min, family = "multinomial", intercept = FALSE)
```


```{r}
saveRDS(lasso, "mnist_lasso.rds")
```

```{r}
readRDS("mnist_lasso.rds")
```



```{r}
y_lasso_dentro <- predict(lasso, newx = X[ids,],
                          s = cv_lasso$lambda.min, type = "class") # valor predito dentro da amostra
# saida mostra a prob de sair determinado valor

# algo esta estranho, pq todas as probabilidades estao iguais

```


```{r}
# comparativo: observado vs predito (dentro da amostra)
(tabela_tr <- table(predito = y_lasso_dentro, observado = y_treino[ids]))

```


```{r}
#
y_lasso_fora <- predict(lasso, newx = X[-ids,],
                        s = cv_lasso$lambda.min, type = "class") # valor predito fora da amostra

```


```{r}
lasso_ac_dentro<- mean(y_lasso_dentro==y_treino[ids])
lasso_ac_fora<- mean(y_lasso_fora==y_treino[-ids])

```

```{r}
resultados <- data.frame("lasso",lasso_ac_dentro, lasso_ac_fora)
names(resultados) <- c("modelo", "acuracia_dentro", "acuracia_fora")

resultados <- resultados %>% mutate(across(where(is.numeric),round,4))
resultados

```

<!-- ```{r} -->
<!-- # labels -->
<!-- pred_labels_tr <- ifelse(pred_probs_tr > 0.5, 1, 0) -->
<!-- # para o calculo alternativo funcionar, substituir 1 e 0 por Yes e No -->

<!-- # comparativo: observado vs predito (dentro da amostra) -->
<!-- (tabela_tr <- table(predito = pred_labels_tr, observado = dados_tr$default)) -->

<!-- # precisao dentro da amostra -->
<!-- (prec_dentro <- (tabela_tr[1, 1] + tabela_tr[2, 2]) / nrow(dados_tr)) -->

<!-- # precisao dentro da amostra (calculo alternativo) -->
<!-- # (prec_dentro <- mean(pred_labels_tr == dados_tr$default)) -->

<!-- # probs fora da amostra -->
<!-- pred_probs_tst <- predict(fit, dados_val, type = "response") -->
<!-- # labels -->
<!-- pred_labels_tst <- ifelse(pred_probs_tst > 0.5, 1, 0) -->

<!-- # comparativo: observado vs predito (fora da amostra) -->
<!-- (tabela_tst <- table(predito = pred_labels_tst, observado = dados_val$default)) -->

<!-- # precisao fora da amostra -->
<!-- (prec_fora <- (tabela_tst[1, 1] + tabela_tst[2, 2]) / nrow(dados_val)) -->

<!-- # precisao dentro da amostra (calculo alternativo) -->
<!-- # (prec_fora <- mean(pred_labels_tst == digitos_tst$digito) * 100) -->

<!-- # salvar resultados em um dataframe -->
<!-- resultados <- data.frame(modelo = c("Reg. Logística", "Naive Bayes", "kNN"), -->
<!--                          prec_dentro = NA, -->
<!--                          prec_fora = NA) -->

<!-- resultados[resultados$modelo == "Reg. Logística", 2:3] <- c(prec_dentro, prec_fora) -->
<!-- resultados -->

<!-- ``` -->


Acuracia/Precisao (confirmar nomes)

algoritmo
se acertou, 1. se errou, 0
soma e divide por nrow

```{r}
# acertou <- ifelse (y_treino==predito,1,0)
# acuracia <- sum(acertou)/nrow(X)
```



```{r}
# (lasso_erro_dentro <- mean((y_lasso_dentro - y_treino[ids])^2))
# 
# (lasso_erro_fora <- mean((y_lasso_fora - y_treino[-ids])^2))
```


```{r}
# resultados[which(resultados$modelo=="lasso"), 2:3] = c(lasso_erro_dentro, lasso_erro_fora)
# resultados


```


### Modelo de Árvores
```{r}
library(tree) # funcoes para estimar arvore de reg/class
library(randomForest) # funcoes para estimar floresta aleatoria

```


```{r}
modelo_rf <- randomForest(factor(db_digitos$y_treino[ids]) ~ .,
                    data = db_digitos[ids, ])
```


```{r}
# importancia das variaveis
importance(modelo_rf)
varImpPlot(modelo_rf)
```

```{r}
y_rf_dentro<- predict(modelo_rf, db_digitos[ids,-1],type="class")
y_rf_fora<- predict(modelo_rf, db_digitos[-ids,-1],type="class")
```


```{r}
# acuracia
rf_ac_dentro <- mean(y_rf_dentro == db_digitos$y_treino[ids])
rf_ac_fora <- mean(y_rf_fora == db_digitos$y_treino[-ids])
```


```{r}
sum(y_rf_dentro==y_treino[ids],na.rm = TRUE)/length(y_treino[ids])
sum(y_rf_fora==y_treino[-ids],na.rm = TRUE)/length(y_treino[-ids])
```


```{r}
# TAREFA: diminuir o numero de arvores do randomForest

# atualizacao do dataframe de resultados
resultados[resultados$modelo=="rf", 2] <- prec_fora_rf

resultados

```

### Redes neurais
Como temos mais de uma classificação, foi utilizado a função softmax como função de ativação.


### Avaliação dos modelos

Para avaliar os modelos, será utilizada a acurácia (erro total de classificação).



1- Modelos lineares com regularização 

2- Modelos baseados em árvores (bagging, florestas aleatórias ou boosting) 

3- Redes neurais 



### Conjunto de teste

Posteriormente, vamos disponibilizar um conjunto de dados de teste, que estará organizado no mesmo formato que o conjunto x_treino. Entretanto, para este conjunto de dados de teste, você não terá acesso às verdadeiras etiquetas de cada imagem. Sua tarefa é estimar um modelo preditivo, realizar predições para as observações do conjunto de teste e submeter um arquivo .csv com o resultado. A medida utilizada para a avaliação dos resultados será a acurácia, isto é, a proporção de imagens corretamente classificadas.
Submissão dos resultados

Em posse do arquivo de dados de teste, use o código abaixo para criar o arquivo para submissão dos seus resultados. Para que funcione, você deverá salvar a predição das imagens de teste em um vetor chamado predicoes. Em seguida, altere o nome do arquivo abaixo, para que tenha seu nome e seu número USP. Arquivos enviados seguindo uma especificação diferente da apresentada abaixo serão desconsiderados.



Submissão dos resultados

Em posse do arquivo de dados de teste, use o código abaixo para criar o arquivo para submissão dos seus resultados. Para que funcione, você deverá salvar a predição das imagens de teste em um vetor chamado predicoes. Em seguida, altere o nome do arquivo abaixo, para que tenha seu nome e seu número USP. Arquivos enviados seguindo uma especificação diferente da apresentada abaixo serão desconsiderados.

```{r}
# write.csv(data.frame(y_pred = predicoes), file="mnist_9297784_yugooyama.csv")

```
